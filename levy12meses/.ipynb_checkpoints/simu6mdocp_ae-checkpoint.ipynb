{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a311c3ac-5f1c-423f-9597-84b69cc6694a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nadia/indicador/lib/python3.10/site-packages/skcriteria/pipeline.py:27: SKCriteriaDeprecationWarning: The 'skcriteria.pipeline' module is deprecated since 0.9 and will be removed in 1.0 Use 'skcriteria.pipelines' instead.\n",
      "  deprecate.warn(\n",
      "/home/nadia/indicador/lib/python3.10/site-packages/skcriteria/madm.py:30: SKCriteriaDeprecationWarning: 'skcriteria.madm' module is deprecated, use 'skcriteria.agg' instead\n",
      "  utils.deprecate.warn(deprecation_reason)\n",
      "/home/nadia/indicador/lib/python3.10/site-packages/skcriteria/agg/similarity.py:27: SKCriteriaDeprecationWarning: The module 'skcriteria.agg.similarity' is deprecated since v0.9 and will be removed in v1.0. Please use 'skcriteria.agg.topsis' instead.\n",
      "  deprecate.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import joblib\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools \n",
    "from itertools import product\n",
    "from collections import Counter\n",
    "import garpar as gp\n",
    "import re\n",
    "import skcriteria as skc\n",
    "from skcriteria import pipeline\n",
    "from skcriteria.preprocessing import invert_objectives, weighters, scalers\n",
    "from skcriteria.madm import similarity, moora, electre\n",
    "from skcriteria.ranksrev import RankInvariantChecker\n",
    "from garpar.datasets import make_multisector, RissoLevyStable, RissoNormal, RissoUniform\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ce7976-dc73-4301-a4d1-f13729c63e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Definici칩n de Nombres (Tickers) ---\n",
    "nombres_acciones = [\n",
    "    \"CRES\", \"CADO\", \"GARO\", \"INVJ\",                                     # AGRO\n",
    "    \"CVH\", \"TECO2\", \"AUSO\", \"BOLT\", \"CTIO\", \"DYCA\", \"GAMI\", \"GCLA\",     # COME (1-8)\n",
    "    \"IRSA\", \"OEST\", \"PATA\", \"POLL\", \"TGLT\",                             # COME (9-13)\n",
    "    \"CEPU\", \"COME\", \"EDN\", \"PAMP\", \"TGNO4\", \"TGSU2\", \"TRAN\", \"YPFD\",    # ENE (1-8)\n",
    "    \"CAPX\", \"CARC\", \"CECO2\", \"CGPA2\", \"DGCU2\", \"GBAN\", \"METR\", \"MTR\",   # ENE (9-16)\n",
    "    \"BBAR\", \"BMA\", \"BYMA\", \"GGAL\", \"SUPV\", \"VALO\", \"BHIP\", \"BPAT\",      # FIN\n",
    "    \"CELU\", \"GRIM\", \"HAVA\", \"INTR\", \"LEDE\", \"MOLA\", \"MOLI\", \"MORI\",     # MOA (1-8)\n",
    "    \"RICH\", \"SAMI\", \"SEMI\",                                             # MOA (9-11)\n",
    "    \"ALUA\", \"HARG\", \"LOMA\", \"MIRG\", \"TXAR\", \"AGRO\", \"DOME\", \"FERR\",     # MOI (1-8)\n",
    "    \"FIPL\", \"LONG\", \"RIGO\"                                              # MOI (9-11)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20353bfe-3027-417a-acb6-c085fd67a3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando 100 simulaciones para Ventana: 3 d칤as...\n",
      "Iniciando 100 simulaciones para Ventana: 5 d칤as...\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Configuraci칩n de Par치metros Fijos ---\n",
    "NUM_ITERACIONES = 100\n",
    "DIAS_SIMULACION = 100\n",
    "VENTANAS_A_PROBAR = [3, 5, 7] \n",
    "\n",
    "# --- 2. Precios Iniciales (Lista Completa) ---\n",
    "PRECIOS_INICIALES_TOTAL = [\n",
    "    1515.00, 475.50, 200.00, 325.00,                      # AGRO (4)\n",
    "    7000.00, 2490.00, 2725.00, 44.85, 1880.00, 840.00,    # COME (1-6)\n",
    "    235.75, 2750.00, 2015.00, 710.00, 1300.00, 300.00,    # COME (7-12)\n",
    "    20.90,                                                # COME (13)\n",
    "    1655.00, 131.25, 1950.00, 4130.00, 3345.00, 7840.00,  # ENE (1-6)\n",
    "    2630.00, 45600.00, 5150.00, 29.95, 407.00, 2420.00,   # ENE (7-12)\n",
    "    1590.00, 1945.00, 2160.00, 2600.00,                   # ENE (13-16)\n",
    "    7140.00, 9420.00, 206.75, 6870.00, 2830.00, 365.50,   # FIN (1-6)\n",
    "    419.00, 2265.00,                                      # FIN (7-8)\n",
    "    311.00, 2150.00, 5900.00, 400.00, 1010.00, 24450.00,  # MOA (1-6)\n",
    "    3060.00, 224.00, 1500.00, 636.00, 25.55,              # MOA (7-11)\n",
    "    787.00, 1550.00, 3195.00, 23500.00, 696.00, 49.60,    # MOI (1-6)\n",
    "    70.00, 25.85, 240.00, 27.00, 670.00                   # MOI (7-11)\n",
    "]\n",
    "# --- DEFINICI칍N DE PAR츼METROS INDEPENDIENTES ---\n",
    "# Par치metros con colas m치s pesadas (Alpha reducido en un 20% para aumentar Curtosis)\n",
    "params_AGRO = {\"alpha\": 1.450000, \"beta\": -0.294056, \"mu\": -0.000443, \"sigma\": 0.012255, \"entropy\": 0.99}\n",
    "params_COME = {\"alpha\": 1.550000, \"beta\": 0.097854, \"mu\": -0.000200, \"sigma\": 0.011113, \"entropy\": 0.99}\n",
    "params_ENE  = {\"alpha\": 1.600000, \"beta\": -0.999961, \"mu\": -0.000073, \"sigma\": 0.017229, \"entropy\": 0.99}\n",
    "params_FIN  = {\"alpha\": 1.500000, \"beta\": 0.154295, \"mu\": 0.000555, \"sigma\": 0.018549, \"entropy\": 0.99}\n",
    "params_MOA  = {\"alpha\": 1.350000, \"beta\": -0.296685, \"mu\": -0.002299, \"sigma\": 0.012174, \"entropy\": 0.99}\n",
    "params_MOI  = {\"alpha\": 1.520000, \"beta\": -0.658029, \"mu\": -0.001496, \"sigma\": 0.013477, \"entropy\": 0.99}\n",
    "\n",
    "# AJUSTE AUTOM츼TICO DE STOCKS_TOTALES\n",
    "STOCKS_TOTALES = len(PRECIOS_INICIALES_TOTAL) # Esto ahora ser치 63\n",
    "\n",
    "# --- 3. Definici칩n de Par치metros (Asegurando 63 entradas) ---\n",
    "# Usamos multiplicadores para no equivocarnos en la cuenta\n",
    "parametros_sectores_base = (\n",
    "    [params_AGRO] * 4 + \n",
    "    [params_COME] * 13 + \n",
    "    [params_ENE] * 16 + \n",
    "    [params_FIN] * 8 + \n",
    "    [params_MOA] * 11 + \n",
    "    [params_MOI] * 11\n",
    ")\n",
    "\n",
    "# Verificaci칩n de seguridad\n",
    "if len(parametros_sectores_base) != STOCKS_TOTALES:\n",
    "    print(f\"ERROR: Tienes {len(parametros_sectores_base)} par치metros pero {STOCKS_TOTALES} precios.\")\n",
    "\n",
    "# --- 4. BUCLE DE SIMULACI칍N ---\n",
    "resultados_por_ventana = {ventana: [] for ventana in VENTANAS_A_PROBAR}\n",
    "\n",
    "for VENTANA in VENTANAS_A_PROBAR:\n",
    "    print(f\"Iniciando {NUM_ITERACIONES} simulaciones para Ventana: {VENTANA} d칤as...\")\n",
    "    \n",
    "    for i in range(NUM_ITERACIONES):\n",
    "        random_seed_base = i * 10000 \n",
    "        distribuciones_para_corrida = []\n",
    "        \n",
    "        for j, params in enumerate(parametros_sectores_base):\n",
    "            semilla_sector = random_seed_base + (j * 100)\n",
    "            params_corrida = params.copy() \n",
    "            params_corrida['random_state'] = semilla_sector\n",
    "            # Se asume que RissoLevyStable est치 importada correctamente\n",
    "            distribuciones_para_corrida.append(RissoLevyStable(**params_corrida))\n",
    "\n",
    "        # SIMULACI칍N DEL MERCADO\n",
    "        stocksset = make_multisector(\n",
    "            *distribuciones_para_corrida,\n",
    "            stocks=STOCKS_TOTALES,  # Ahora es 63\n",
    "            days=DIAS_SIMULACION,\n",
    "            window_size=VENTANA,\n",
    "            price=PRECIOS_INICIALES_TOTAL \n",
    "        )\n",
    "        \n",
    "        df_simulacion = stocksset._prices_df \n",
    "        resultados_por_ventana[VENTANA].append(df_simulacion)\n",
    "    \n",
    "print(\"\\n--- 춰Generaci칩n de Simulaciones Finalizada! ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70796789-6a8e-44cc-8ce9-bd7058ef5d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Definici칩n de Nombres de Acciones (Fuera del bucle) ---\n",
    "nombres_acciones = [\n",
    "    \"CRES\", \"CADO\", \"GARO\", \"INVJ\",                                     # AGRO\n",
    "    \"CVH\", \"TECO2\", \"AUSO\", \"BOLT\", \"CTIO\", \"DYCA\", \"GAMI\", \"GCLA\",     # COME (1-8)\n",
    "    \"IRSA\", \"OEST\", \"PATA\", \"POLL\", \"TGLT\",                             # COME (9-13)\n",
    "    \"CEPU\", \"COME\", \"EDN\", \"PAMP\", \"TGNO4\", \"TGSU2\", \"TRAN\", \"YPFD\",    # ENE (1-8)\n",
    "    \"CAPX\", \"CARC\", \"CECO2\", \"CGPA2\", \"DGCU2\", \"GBAN\", \"METR\", \"MTR\",   # ENE (9-16)\n",
    "    \"BBAR\", \"BMA\", \"BYMA\", \"GGAL\", \"SUPV\", \"VALO\", \"BHIP\", \"BPAT\",      # FIN\n",
    "    \"CELU\", \"GRIM\", \"HAVA\", \"INTR\", \"LEDE\", \"MOLA\", \"MOLI\", \"MORI\",     # MOA (1-8)\n",
    "    \"RICH\", \"SAMI\", \"SEMI\",                                             # MOA (9-11)\n",
    "    \"ALUA\", \"HARG\", \"LOMA\", \"MIRG\", \"TXAR\", \"AGRO\", \"DOME\", \"FERR\",     # MOI (1-8)\n",
    "    \"FIPL\", \"LONG\", \"RIGO\"                                              # MOI (9-11)\n",
    "]\n",
    "\n",
    "# --- 6. Ensamblado: Asignaci칩n de Nombres a los DataFrames Resultantes ---\n",
    "# Recorremos el diccionario generado en el paso 4 y renombramos las columnas\n",
    "for ventana in VENTANAS_A_PROBAR:\n",
    "    for df in resultados_por_ventana[ventana]:\n",
    "        # Asignamos los nombres directamente a las columnas del DataFrame\n",
    "        df.columns = nombres_acciones\n",
    "\n",
    "print(\"--- Nombres de acciones integrados correctamente en todos los DataFrames ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bac701-66b1-46f6-8309-67b991c6bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0. CONFIGURACI칍N INICIAL ---\n",
    "# Suprimir el warning com칰n de garpar/pypfopt sobre matrices no positivas\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message='The covariance matrix is non positive semidefinite. Amending eigenvalues.')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message=\"No risk_free_rate specified, coercing it\")\n",
    "# 丘멆잺 DEFINICI칍N DE LOS OPTIMIZADORES A PROBAR (Asumida)\n",
    "optimizadores_a_probar = {\n",
    "  #  \"max_sharpe\": gp.optimize.mean_variance.MVOptimizer(model='max_sharpe'),\n",
    "    \"Markowitz sujeto a retorno m칤nimo 0.001\": gp.optimize.mean_variance.Markowitz(target_return=0.001),\n",
    "    \"Markowitz sujeto a retorno m칤nimo 0.002\": gp.optimize.mean_variance.Markowitz(target_return=0.002),\n",
    "    \"Markowitz sujeto a retorno m칤nimo 0.003\": gp.optimize.mean_variance.Markowitz(target_return=0.003),\n",
    "    \"Markowitz sujeto a retorno m칤nimo 0.004\": gp.optimize.mean_variance.Markowitz(target_return=0.004),\n",
    "    \"Markowitz sujeto a retorno m칤nimo 0.005\": gp.optimize.mean_variance.Markowitz(target_return=0.005),\n",
    "#    \"markowitz_target_risk1\": gp.optimize.mean_variance.Markowitz(target_risk=0.36),\n",
    "\n",
    "}\n",
    "\n",
    "rows = []\n",
    "\n",
    "print(\"--- INICIO DEL PROCESAMIENTO DE M칄TRICAS (Usando StocksSet) ---\")\n",
    "\n",
    "# --- 1. BUCLE DE PROCESAMIENTO SOBRE LOS RESULTADOS GUARDADOS ---\n",
    "\n",
    "for VENTANA, lista_simulaciones in resultados_por_ventana.items():\n",
    "    \n",
    "    for i, df_corrida in enumerate(lista_simulaciones):\n",
    "        \n",
    "        corrida_id = i + 1\n",
    "        stocks_number_base = len(df_corrida.columns)\n",
    "\n",
    "        # 游눠 MEJORA DE ROBUSTEZ: Intentar crear el StocksSet primero\n",
    "        stocksset_corrida = None\n",
    "        try:\n",
    "            stocksset_corrida = gp.StocksSet.from_prices(df_corrida, window_size=VENTANA)\n",
    "        except Exception as e:\n",
    "            # Si el StocksSet falla (ej: datos malformados), registra el fallo para TODOS los modelos\n",
    "            print(f\"丘멆잺 Error al crear StocksSet (Corrida {corrida_id}, Ventana {VENTANA}): {e}. Saltando modelos.\")\n",
    "            \n",
    "            for opt_name in optimizadores_a_probar.keys():\n",
    "                rows.append({\n",
    "                    \"Ventana\": VENTANA,\n",
    "                    \"Corrida\": corrida_id,\n",
    "                    \"Modelo_Opt\": opt_name,\n",
    "                    \"stocks_number\": stocks_number_base, \n",
    "                    \"Cross_Entropy\": np.nan,\n",
    "                    \"Zheng_Entropy\": np.nan,\n",
    "                    \"Div_Ratio\": np.nan,\n",
    "                    \"CV_MC\": np.nan,\n",
    "                    \"PDI\": np.nan\n",
    "                })\n",
    "            continue # Pasa a la siguiente corrida\n",
    "        \n",
    "        # 2. ITERACI칍N SOBRE LOS MODELOS DE OPTIMIZACI칍N\n",
    "        for opt_name, optimizador in optimizadores_a_probar.items():\n",
    "            \n",
    "            try:\n",
    "                # 3. OPTIMIZACI칍N + PRUNING\n",
    "                mopt = optimizador.optimize(stocksset_corrida).weights_prune()\n",
    "                \n",
    "                # 4. C츼LCULO DE M칄TRICAS (EXITOSO)\n",
    "                metricas = {\n",
    "                    \"stocks_number\": len(mopt.stocks),\n",
    "                    \"Cross_Entropy\": mopt.div.cross_entropy(),\n",
    "                    \"Zheng_Entropy\": mopt.div.zheng_entropy(),\n",
    "                    \"Div_Ratio\": mopt.div.ratio(),\n",
    "                    \"CV_MC\": (mopt.div.mrc() * mopt.weights).std() / (mopt.div.mrc() * mopt.weights).mean(),\n",
    "                    \"PDI\": mopt.div.pdi(n_components=3, random_state=100)\n",
    "                }\n",
    "\n",
    "                # 5. GUARDAR RESULTADO EXITOSO\n",
    "                rows.append({\n",
    "                    \"Ventana\": VENTANA,\n",
    "                    \"Corrida\": corrida_id,\n",
    "                    \"Modelo_Opt\": opt_name, \n",
    "                    **metricas\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                #  Garantizar que la fila de identificadores se guarde\n",
    "                rows.append({\n",
    "                    \"Ventana\": VENTANA,\n",
    "                    \"Corrida\": corrida_id,\n",
    "                    \"Modelo_Opt\": opt_name,\n",
    "                    \"stocks_number\": stocks_number_base, \n",
    "                    \"Cross_Entropy\": np.nan,\n",
    "                    \"Zheng_Entropy\": np.nan,\n",
    "                    \"Div_Ratio\": np.nan,\n",
    "                    \"CV_MC\": np.nan,\n",
    "                    \"PDI\": np.nan\n",
    "                })\n",
    "            \n",
    "# --- 2. CREACI칍N DEL DATAFRAME FINAL ---\n",
    "\n",
    "df_metricas_simulacion = pd.DataFrame(rows)\n",
    "\n",
    "# Esta l칤nea ahora es segura, ya que 'rows' garantiza las claves de 칤ndice\n",
    "df_metricas_simulacion = df_metricas_simulacion.set_index([\"Ventana\", \"Corrida\", \"Modelo_Opt\"])\n",
    "\n",
    "print(\"\\n--- AN츼LISIS COMPLETADO ---\")\n",
    "print(f\"Total de resultados guardados: {len(df_metricas_simulacion)} filas.\")\n",
    "print(df_metricas_simulacion.head(9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9bf594-2a78-4829-b21d-168bb0836579",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metricas_simulacion[(df_metricas_simulacion.index.get_level_values('Ventana') == 3) &\n",
    "    (df_metricas_simulacion.index.get_level_values('Corrida') ==10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a92d1b7-e9d7-46c1-abb6-8f30d16c7a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metricas_simulacion[(df_metricas_simulacion.index.get_level_values('Ventana') == 3) &\n",
    "    (df_metricas_simulacion.index.get_level_values('Corrida') ==12)].droplevel('Ventana').droplevel('Corrida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc477884-41c4-46aa-b22b-ddfeec29fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminar corridas con NaN ===\n",
    "# =========================================================================\n",
    "\n",
    "# 1. Identificar el nivel del 칤ndice que representa la \"corrida\"\n",
    "LEVEL_CORRIDA = 'Corrida' \n",
    "\n",
    "# 2. Inicializar una lista para guardar las corridas (칤ndices) que deben eliminarse\n",
    "corridas_a_eliminar = set()\n",
    "\n",
    "# 3. Iterar sobre las corridas (grupos) para verificar NaNs\n",
    "for corrida_id, group_df in df_metricas_simulacion.groupby(level=LEVEL_CORRIDA):\n",
    "    \n",
    "    # 4. Verificar si existe AL MENOS UN NaN en CUALQUIERA de las filas\n",
    "    # .isnull() crea un DF booleano, .any(axis=None) verifica si hay True en todo el grupo.\n",
    "    if group_df.isnull().any().any(): \n",
    "        # Si se encuentra un NaN, se a침ade el ID de la corrida a la lista de eliminaci칩n\n",
    "        corridas_a_eliminar.add(corrida_id)\n",
    "\n",
    "# 5. Filtrar el DataFrame original, excluyendo las corridas identificadas\n",
    "# Creamos una m치scara booleana: True para las corridas que NO est치n en la lista\n",
    "mascara_mantener = ~df_metricas_simulacion.index.get_level_values(LEVEL_CORRIDA).isin(corridas_a_eliminar)\n",
    "\n",
    "# Aplicar la m치scara al DataFrame\n",
    "df_metricas_limpio = df_metricas_simulacion[mascara_mantener]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4f4c03-39ff-4383-9801-1bf6ed62bc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metricas_limpio[df_metricas_limpio.index.get_level_values('Ventana') == 3].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059d90e9-a892-4b9c-85d2-4dd9c342f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# === Definiciones \n",
    "# =========================================================================\n",
    "\n",
    "# 1. Definici칩n de Objetivos (id칠ntica a tu c칩digo)\n",
    "objectives = [\n",
    "    max, # 'stocks_number'\n",
    "    min, # 'Cross_Entropy'\n",
    "    max, # 'Zheng_Entropy'\n",
    "    max, # 'Div_Ratio'\n",
    "    min, # 'CV_MC'\n",
    "    max, # 'PDI'\n",
    "]\n",
    "\n",
    "# 2. Identificar el nivel 'Ventana' que quieres filtrar (parece ser '3')\n",
    "VENTANA_FILTRO = 3\n",
    "LEVEL_VENTANA = 'Ventana'\n",
    "LEVEL_CORRIDA = 'Corrida'\n",
    "\n",
    "# 3. Filtrar por Ventana = 3 (esto simplifica la iteraci칩n)\n",
    "df_ventana_3 = df_metricas_limpio[\n",
    "    df_metricas_limpio.index.get_level_values(LEVEL_VENTANA) == VENTANA_FILTRO].copy()\n",
    "\n",
    "# === PASO CR칈TICO: OBTENER LOS IDs DE CORRIDA REALES ===\n",
    "# =========================================================================\n",
    "# Obtenemos la lista 칔NICA de los identifi}cadores de corrida que existen \n",
    "corridas_existentes_v3 = df_ventana_3.index.get_level_values('Corrida').unique().tolist()\n",
    "corridas_existentes_v3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3c9133-c8a7-4984-a882-1c90073ad2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario para almacenar las Matrices de Decisi칩n generadas\n",
    "matrices_decision = {}\n",
    "\n",
    "# Iteramos sobre los IDs de corrida REALES (ej: '10', '11'...)\n",
    "for el_corrida_id in corridas_existentes_v3:\n",
    "\n",
    "    # 1. Filtramos el DataFrame de M칄TRICAS para la corrida actual\n",
    "    df_filtrado = df_ventana_3[df_ventana_3.index.get_level_values('Corrida') == el_corrida_id].droplevel(['Ventana', 'Corrida'])\n",
    "    \n",
    "    # 2. ACCESO AL DATAFRAME ORIGINAL DE PESOS (Variable nueva solicitada)\n",
    "\n",
    "    # === Extracci칩n de elementos para skcriteria ===\n",
    "    data = df_filtrado.to_numpy() \n",
    "    alternatives = df_filtrado.index \n",
    "    criteria = df_filtrado.columns \n",
    "    \n",
    "    # === Generar la Matriz de Decisi칩n ===\n",
    "    dm = skc.mkdm(\n",
    "        data, \n",
    "        objectives=objectives,\n",
    "        alternatives=alternatives, \n",
    "        criteria=criteria\n",
    "    )\n",
    "    \n",
    "    # Guardar la DM\n",
    "    matrices_decision[el_corrida_id] = dm\n",
    "matrices_decision[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6344bbc0-da07-40ae-81d7-67bd263d4fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Definici칩n del Pipeline\n",
    "pipe_igual_vector = pipeline.mkpipe(\n",
    "    invert_objectives.NegateMinimize(),\n",
    "    scalers.VectorScaler(target=\"matrix\"),\n",
    "    weighters.EqualWeighter(),\n",
    "    similarity.TOPSIS(),\n",
    ")\n",
    "# VARIABLE NUEVA: Lista para acumular los resultados de similaridad\n",
    "resultados_similaridad = []\n",
    "\n",
    "for el_corrida_id in corridas_existentes_v3:\n",
    "    \n",
    "    # 1. Recuperamos la DM del diccionario generado anteriormente\n",
    "    dm = matrices_decision[el_corrida_id]\n",
    "    \n",
    "    # 2. Ejecuci칩n del pipeline\n",
    "    result_igual_vector = pipe_igual_vector.evaluate(dm)\n",
    "    \n",
    "    # === CORRECCI칍N DEL ERROR Y CAMBIO DE NOMBRE ===\n",
    "    # Convertimos el array de numpy (result_igual_vector.e_.similarity) a DataFrame\n",
    "    # Usamos las alternativas de la DM como nombres de columnas\n",
    "    df_similaridad_parcial = pd.DataFrame(\n",
    "        [result_igual_vector.e_.similarity], \n",
    "        columns=dm.alternatives, \n",
    "        index=[el_corrida_id]\n",
    "    )\n",
    "    \n",
    "    # 3. Guardamos en la lista para concatenar despu칠s\n",
    "    resultados_similaridad.append(df_similaridad_parcial)\n",
    "\n",
    "# 4. CREACI칍N DEL DATAFRAME FINAL (VARIABLE NUEVA)\n",
    "df_similaridad_total_v3 = pd.concat(resultados_similaridad)\n",
    "df_similaridad_total_v3.index.name = 'Corrida'\n",
    "\n",
    "# Visualizar resultado consolidado de similaridad\n",
    "df_similaridad_total_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a483bef2-55de-49ae-bb1d-649764e14426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configuraci칩n de la grilla (Forzada a 1 fila de 5 columnas)\n",
    "modelos = df_similaridad_total_v3.columns\n",
    "n_modelos = len(modelos)\n",
    "n_cols = 5  # Cambiado a 5 para que entren todos en una fila\n",
    "n_rows = 1  # Forzado a 1 rengl칩n\n",
    "\n",
    "# 2. Crear la figura y los subplots\n",
    "# He aumentado el ancho (25) para que los 5 gr치ficos tengan espacio\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(25, 5), sharey=True, sharex=False)\n",
    "\n",
    "# 3. Bucle para generar cada histograma\n",
    "for i, modelo in enumerate(modelos):\n",
    "    # Si solo hay una fila, axes puede no ser una matriz, lo tratamos con cuidado\n",
    "    ax = axes[i] if n_modelos > 1 else axes\n",
    "    \n",
    "    # Generar el histograma con densidad\n",
    "    ax.hist(df_similaridad_total_v3[modelo], bins=15, color='skyblue', \n",
    "            edgecolor='black', alpha=0.7, density=True)\n",
    "    \n",
    "    # Configuraci칩n del t칤tulo\n",
    "    ax.set_title(f'Desempe침o ventana 3 d칤as \\n para {modelo} \\n con distribuci칩n levy del mercado \\n y entrop칤a baja ', fontsize=10)\n",
    "\n",
    "    ax.set_xlabel('Similaridad')\n",
    "    # Solo ponemos el label del eje Y en el primero para no saturar\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('Densidad (Frec. Relativa)')\n",
    "        \n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Limpiar subplots vac칤os (en caso de que haya menos de 5 modelos)\n",
    "if n_modelos < n_cols:\n",
    "    for j in range(i + 1, n_cols):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "# Ajustar espaciado\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14200172-52c9-428d-9d9f-bf147537548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# === Definiciones \n",
    "# =========================================================================\n",
    "\n",
    "# 1. Definici칩n de Objetivos (id칠ntica a tu c칩digo)\n",
    "objectives = [\n",
    "    max, # 'stocks_number'\n",
    "    min, # 'Cross_Entropy'\n",
    "    max, # 'Zheng_Entropy'\n",
    "    max, # 'Div_Ratio'\n",
    "    min, # 'CV_MC'\n",
    "    max, # 'PDI'\n",
    "]\n",
    "\n",
    "# 2. Identificar el nivel 'Ventana' que quieres filtrar (parece ser '3')\n",
    "VENTANA_FILTRO = 5\n",
    "LEVEL_VENTANA = 'Ventana'\n",
    "LEVEL_CORRIDA = 'Corrida'\n",
    "\n",
    "# 3. Filtrar por Ventana = 3 (esto simplifica la iteraci칩n)\n",
    "df_ventana_5 = df_metricas_limpio[\n",
    "    df_metricas_limpio.index.get_level_values(LEVEL_VENTANA) == VENTANA_FILTRO].copy()\n",
    "\n",
    "# === PASO CR칈TICO: OBTENER LOS IDs DE CORRIDA REALES ===\n",
    "# =========================================================================\n",
    "# Obtenemos la lista 칔NICA de los identifi}cadores de corrida que existen \n",
    "corridas_existentes_v5 = df_ventana_3.index.get_level_values('Corrida').unique().tolist()\n",
    "corridas_existentes_v5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4884ad6-5beb-485e-a4a6-4239b1bc17e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario para almacenar las Matrices de Decisi칩n generadas\n",
    "matrices_decision = {}\n",
    "\n",
    "# Iteramos sobre los IDs de corrida REALES (ej: '10', '11'...)\n",
    "for el_corrida_id in corridas_existentes_v5:\n",
    "\n",
    "    # 1. Filtramos el DataFrame de M칄TRICAS para la corrida actual\n",
    "    df_filtrado = df_ventana_5[df_ventana_5.index.get_level_values('Corrida') == el_corrida_id].droplevel(['Ventana', 'Corrida'])\n",
    "    \n",
    "    # 2. ACCESO AL DATAFRAME ORIGINAL DE PESOS (Variable nueva solicitada)\n",
    "\n",
    "    # === Extracci칩n de elementos para skcriteria ===\n",
    "    data = df_filtrado.to_numpy() \n",
    "    alternatives = df_filtrado.index \n",
    "    criteria = df_filtrado.columns \n",
    "    \n",
    "    # === Generar la Matriz de Decisi칩n ===\n",
    "    dm = skc.mkdm(\n",
    "        data, \n",
    "        objectives=objectives,\n",
    "        alternatives=alternatives, \n",
    "        criteria=criteria\n",
    "    )\n",
    "    \n",
    "    # Guardar la DM\n",
    "    matrices_decision[el_corrida_id] = dm\n",
    "matrices_decision[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3df1b01-c404-4d5a-9694-432a6246cd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Definici칩n del Pipeline\n",
    "pipe_igual_vector = pipeline.mkpipe(\n",
    "    invert_objectives.NegateMinimize(),\n",
    "    scalers.VectorScaler(target=\"matrix\"),\n",
    "    weighters.EqualWeighter(),\n",
    "    similarity.TOPSIS(),\n",
    ")\n",
    "# VARIABLE NUEVA: Lista para acumular los resultados de similaridad\n",
    "resultados_similaridad = []\n",
    "\n",
    "for el_corrida_id in corridas_existentes_v3:\n",
    "    \n",
    "    # 1. Recuperamos la DM del diccionario generado anteriormente\n",
    "    dm = matrices_decision[el_corrida_id]\n",
    "    \n",
    "    # 2. Ejecuci칩n del pipeline\n",
    "    result_igual_vector = pipe_igual_vector.evaluate(dm)\n",
    "    \n",
    "    # === CORRECCI칍N DEL ERROR Y CAMBIO DE NOMBRE ===\n",
    "    # Convertimos el array de numpy (result_igual_vector.e_.similarity) a DataFrame\n",
    "    # Usamos las alternativas de la DM como nombres de columnas\n",
    "    df_similaridad_parcial = pd.DataFrame(\n",
    "        [result_igual_vector.e_.similarity], \n",
    "        columns=dm.alternatives, \n",
    "        index=[el_corrida_id]\n",
    "    )\n",
    "    \n",
    "    # 3. Guardamos en la lista para concatenar despu칠s\n",
    "    resultados_similaridad.append(df_similaridad_parcial)\n",
    "\n",
    "# 4. CREACI칍N DEL DATAFRAME FINAL (VARIABLE NUEVA)\n",
    "df_similaridad_total_v5 = pd.concat(resultados_similaridad)\n",
    "df_similaridad_total_v5.index.name = 'Corrida'\n",
    "\n",
    "# Visualizar resultado consolidado de similaridad\n",
    "df_similaridad_total_v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d915aa75-eb3b-4023-9071-6aa147700f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configuraci칩n de la grilla (Forzada a 1 fila de 5 columnas)\n",
    "modelos = df_similaridad_total_v5.columns\n",
    "n_modelos = len(modelos)\n",
    "n_cols = 5  # Cambiado a 5 para que entren todos en una fila\n",
    "n_rows = 1  # Forzado a 1 rengl칩n\n",
    "\n",
    "# 2. Crear la figura y los subplots\n",
    "# He aumentado el ancho (25) para que los 5 gr치ficos tengan espacio\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(25, 5), sharey=True, sharex=False)\n",
    "\n",
    "# 3. Bucle para generar cada histograma\n",
    "for i, modelo in enumerate(modelos):\n",
    "    # Si solo hay una fila, axes puede no ser una matriz, lo tratamos con cuidado\n",
    "    ax = axes[i] if n_modelos > 1 else axes\n",
    "    \n",
    "    # Generar el histograma con densidad\n",
    "    ax.hist(df_similaridad_total_v5[modelo], bins=15, color='skyblue', \n",
    "            edgecolor='black', alpha=0.7, density=True)\n",
    "    \n",
    "    # Configuraci칩n del t칤tulo\n",
    "    ax.set_title(f'Desempe침o ventana 5 d칤as \\n para {modelo} \\n con distribuci칩n levy del mercado \\n y entrop칤a baja ', fontsize=10)\n",
    "\n",
    "    ax.set_xlabel('Similaridad')\n",
    "    # Solo ponemos el label del eje Y en el primero para no saturar\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('Densidad (Frec. Relativa)')\n",
    "        \n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Limpiar subplots vac칤os (en caso de que haya menos de 5 modelos)\n",
    "if n_modelos < n_cols:\n",
    "    for j in range(i + 1, n_cols):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "# Ajustar espaciado\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f795c694-d66f-4a8b-a14c-8890dec26faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# === Definiciones \n",
    "# =========================================================================\n",
    "\n",
    "# 1. Definici칩n de Objetivos (id칠ntica a tu c칩digo)\n",
    "objectives = [\n",
    "    max, # 'stocks_number'\n",
    "    min, # 'Cross_Entropy'\n",
    "    max, # 'Zheng_Entropy'\n",
    "    max, # 'Div_Ratio'\n",
    "    min, # 'CV_MC'\n",
    "    max, # 'PDI'\n",
    "]\n",
    "\n",
    "# 2. Identificar el nivel 'Ventana' que quieres filtrar (parece ser '3')\n",
    "VENTANA_FILTRO = 7\n",
    "LEVEL_VENTANA = 'Ventana'\n",
    "LEVEL_CORRIDA = 'Corrida'\n",
    "\n",
    "# 3. Filtrar por Ventana = 3 (esto simplifica la iteraci칩n)\n",
    "df_ventana_7 = df_metricas_limpio[\n",
    "    df_metricas_limpio.index.get_level_values(LEVEL_VENTANA) == VENTANA_FILTRO].copy()\n",
    "\n",
    "# === PASO CR칈TICO: OBTENER LOS IDs DE CORRIDA REALES ===\n",
    "# =========================================================================\n",
    "# Obtenemos la lista 칔NICA de los identifi}cadores de corrida que existen \n",
    "corridas_existentes_v7 = df_ventana_3.index.get_level_values('Corrida').unique().tolist()\n",
    "corridas_existentes_v7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94115da-95c2-4305-be7c-404642221baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario para almacenar las Matrices de Decisi칩n generadas\n",
    "matrices_decision = {}\n",
    "\n",
    "# Iteramos sobre los IDs de corrida REALES (ej: '10', '11'...)\n",
    "for el_corrida_id in corridas_existentes_v5:\n",
    "\n",
    "    # 1. Filtramos el DataFrame de M칄TRICAS para la corrida actual\n",
    "    df_filtrado = df_ventana_7[df_ventana_7.index.get_level_values('Corrida') == el_corrida_id].droplevel(['Ventana', 'Corrida'])\n",
    "    \n",
    "    # 2. ACCESO AL DATAFRAME ORIGINAL DE PESOS (Variable nueva solicitada)\n",
    "\n",
    "    # === Extracci칩n de elementos para skcriteria ===\n",
    "    data = df_filtrado.to_numpy() \n",
    "    alternatives = df_filtrado.index \n",
    "    criteria = df_filtrado.columns \n",
    "    \n",
    "    # === Generar la Matriz de Decisi칩n ===\n",
    "    dm = skc.mkdm(\n",
    "        data, \n",
    "        objectives=objectives,\n",
    "        alternatives=alternatives, \n",
    "        criteria=criteria\n",
    "    )\n",
    "    \n",
    "    # Guardar la DM\n",
    "    matrices_decision[el_corrida_id] = dm\n",
    "matrices_decision[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f938eb0-5053-4ded-9e02-ceb16518f07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Definici칩n del Pipeline\n",
    "pipe_igual_vector = pipeline.mkpipe(\n",
    "    invert_objectives.NegateMinimize(),\n",
    "    scalers.VectorScaler(target=\"matrix\"),\n",
    "    weighters.EqualWeighter(),\n",
    "    similarity.TOPSIS(),\n",
    ")\n",
    "# VARIABLE NUEVA: Lista para acumular los resultados de similaridad\n",
    "resultados_similaridad = []\n",
    "\n",
    "for el_corrida_id in corridas_existentes_v3:\n",
    "    \n",
    "    # 1. Recuperamos la DM del diccionario generado anteriormente\n",
    "    dm = matrices_decision[el_corrida_id]\n",
    "    \n",
    "    # 2. Ejecuci칩n del pipeline\n",
    "    result_igual_vector = pipe_igual_vector.evaluate(dm)\n",
    "    \n",
    "    # === CORRECCI칍N DEL ERROR Y CAMBIO DE NOMBRE ===\n",
    "    # Convertimos el array de numpy (result_igual_vector.e_.similarity) a DataFrame\n",
    "    # Usamos las alternativas de la DM como nombres de columnas\n",
    "    df_similaridad_parcial = pd.DataFrame(\n",
    "        [result_igual_vector.e_.similarity], \n",
    "        columns=dm.alternatives, \n",
    "        index=[el_corrida_id]\n",
    "    )\n",
    "    \n",
    "    # 3. Guardamos en la lista para concatenar despu칠s\n",
    "    resultados_similaridad.append(df_similaridad_parcial)\n",
    "\n",
    "# 4. CREACI칍N DEL DATAFRAME FINAL (VARIABLE NUEVA)\n",
    "df_similaridad_total_v7 = pd.concat(resultados_similaridad)\n",
    "df_similaridad_total_v7.index.name = 'Corrida'\n",
    "\n",
    "# Visualizar resultado consolidado de similaridad\n",
    "df_similaridad_total_v7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87e728-ee0a-46d7-b3e9-fce02b41a297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Definici칩n del Pipeline\n",
    "pipe_igual_vector = pipeline.mkpipe(\n",
    "    invert_objectives.NegateMinimize(),\n",
    "    scalers.VectorScaler(target=\"matrix\"),\n",
    "    weighters.EqualWeighter(),\n",
    "    similarity.TOPSIS(),\n",
    ")\n",
    "# VARIABLE NUEVA: Lista para acumular los resultados de similaridad\n",
    "resultados_similaridad = []\n",
    "\n",
    "for el_corrida_id in corridas_existentes_v3:\n",
    "    \n",
    "    # 1. Recuperamos la DM del diccionario generado anteriormente\n",
    "    dm = matrices_decision[el_corrida_id]\n",
    "    \n",
    "    # 2. Ejecuci칩n del pipeline\n",
    "    result_igual_vector = pipe_igual_vector.evaluate(dm)\n",
    "    \n",
    "    # === CORRECCI칍N DEL ERROR Y CAMBIO DE NOMBRE ===\n",
    "    # Convertimos el array de numpy (result_igual_vector.e_.similarity) a DataFrame\n",
    "    # Usamos las alternativas de la DM como nombres de columnas\n",
    "    df_similaridad_parcial = pd.DataFrame(\n",
    "        [result_igual_vector.e_.similarity], \n",
    "        columns=dm.alternatives, \n",
    "        index=[el_corrida_id]\n",
    "    )\n",
    "    \n",
    "    # 3. Guardamos en la lista para concatenar despu칠s\n",
    "    resultados_similaridad.append(df_similaridad_parcial)\n",
    "\n",
    "# 4. CREACI칍N DEL DATAFRAME FINAL (VARIABLE NUEVA)\n",
    "df_similaridad_total_v7 = pd.concat(resultados_similaridad)\n",
    "df_similaridad_total_v7.index.name = 'Corrida'\n",
    "\n",
    "# Visualizar resultado consolidado de similaridad\n",
    "df_similaridad_total_v7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00697d75-f8b5-453a-8280-bfa38942d178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configuraci칩n de la grilla (Forzada a 1 fila de 5 columnas)\n",
    "modelos = df_similaridad_total_v7.columns\n",
    "n_modelos = len(modelos)\n",
    "n_cols = 5  # Cambiado a 5 para que entren todos en una fila\n",
    "n_rows = 1  # Forzado a 1 rengl칩n\n",
    "\n",
    "# 2. Crear la figura y los subplots\n",
    "# He aumentado el ancho (25) para que los 5 gr치ficos tengan espacio\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(25, 5), sharey=True, sharex=False)\n",
    "\n",
    "# 3. Bucle para generar cada histograma\n",
    "for i, modelo in enumerate(modelos):\n",
    "    # Si solo hay una fila, axes puede no ser una matriz, lo tratamos con cuidado\n",
    "    ax = axes[i] if n_modelos > 1 else axes\n",
    "    \n",
    "    # Generar el histograma con densidad\n",
    "    ax.hist(df_similaridad_total_v7[modelo], bins=15, color='skyblue', \n",
    "            edgecolor='black', alpha=0.7, density=True)\n",
    "    \n",
    "    # Configuraci칩n del t칤tulo\n",
    "    ax.set_title(f'Desempe침o ventana 5 d칤as \\n para {modelo} \\n con distribuci칩n levy del mercado \\n y entrop칤a baja' , fontsize=10)\n",
    "\n",
    "    ax.set_xlabel('Coeficiente Similaridad')\n",
    "    # Solo ponemos el label del eje Y en el primero para no saturar\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('Densidad (Frec. Relativa)')\n",
    "        \n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Limpiar subplots vac칤os (en caso de que haya menos de 5 modelos)\n",
    "if n_modelos < n_cols:\n",
    "    for j in range(i + 1, n_cols):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "# Ajustar espaciado\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e56b2e-4ad5-4b54-a58a-23be3839c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. Configuraci칩n de la figura: 1 fila, 2 columnas\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 7), sharey=True)\n",
    "\n",
    "# 2. Gr치fico 1: Ventana 3 d칤as\n",
    "sns.boxplot(\n",
    "    data=df_similaridad_total_v3, \n",
    "    ax=axes[0], \n",
    "    palette=\"Greys_r\"\n",
    ")\n",
    "axes[0].set_title('Desempe침o modelos con Ventana 3 D칤as \\n con distribuci칩n levy del mercado \\n y entrop칤a baja ', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticklabels(df_similaridad_total_v3.columns, rotation=90)\n",
    "axes[0].set_ylabel('Coeficiente de Similaridad')\n",
    "axes[0].set_xlabel('Modelos')\n",
    "\n",
    "# 3. Gr치fico 2: Ventana 5 d칤as\n",
    "sns.boxplot(\n",
    "    data=df_similaridad_total_v5, \n",
    "    ax=axes[1], \n",
    "    palette=\"Greys_r\"\n",
    ")\n",
    "axes[1].set_title('Desempe침o modelos con Ventana 5 D칤as \\n con distribuci칩n levy del mercado \\n y entrop칤a baja  ', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticklabels(df_similaridad_total_v5.columns, rotation=90)\n",
    "axes[1].set_ylabel('') # Quitamos el label porque comparten eje Y\n",
    "axes[1].set_xlabel('Modelos')\n",
    "\n",
    "# 3. Gr치fico 3: Ventana 5 d칤as\n",
    "sns.boxplot(\n",
    "    data=df_similaridad_total_v7, \n",
    "    ax=axes[2], \n",
    "    palette=\"Greys_r\"\n",
    ")\n",
    "axes[2].set_title('Desempe침o modelos con Ventana 7 D칤as \\n con distribuci칩n levy del mercado \\n y entrop칤a baja ', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xticklabels(df_similaridad_total_v7.columns, rotation=90)\n",
    "axes[2].set_ylabel('') # Quitamos el label porque comparten eje Y\n",
    "axes[2].set_xlabel('Modelos')\n",
    "\n",
    "\n",
    "# Ajustes finales\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b578952-6bdb-4bd7-a946-de260689b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Preparaci칩n: A침adimos la etiqueta de \"Ventana\" a cada DataFrame\n",
    "# Hacemos una copia para no modificar los originales\n",
    "df3 = df_similaridad_total_v3.copy()\n",
    "df5 = df_similaridad_total_v5.copy()\n",
    "df7 = df_similaridad_total_v7.copy()\n",
    "\n",
    "df3['Ventana'] = '3 D칤as'\n",
    "df5['Ventana'] = '5 D칤as'\n",
    "df7['Ventana'] = '7 D칤as'\n",
    "\n",
    "# 2. Concatenamos los tres DataFrames en uno solo\n",
    "df_total = pd.concat([df3, df5, df7], ignore_index=True)\n",
    "\n",
    "# 3. Configuraci칩n del estilo\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "# 4. Creaci칩n del Pairplot\n",
    "# El 'hue' ser치 la Ventana. Esto comparar치 c칩mo correlacionan los modelos entre s칤\n",
    "# y mostrar치 la distribuci칩n (KDE) en la diagonal.\n",
    "g = sns.pairplot(\n",
    "    df_total, \n",
    "    hue=\"Ventana\", \n",
    "    palette=\"viridis\", \n",
    "    diag_kind=\"kde\",\n",
    "    plot_kws={'alpha': 0.6, 's': 30, 'edgecolor': 'k'}, # Ajustes para los puntos\n",
    "    height=2.5\n",
    ")\n",
    "\n",
    "# A침adir t칤tulo general\n",
    "g.fig.suptitle('Relaci칩n de Desempe침o entre Modelos y Ventanas de Tiempo', y=1.02, fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c943a8-51b4-4fa0-85b5-2be25ecd1203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configuraci칩n de la figura: 1 fila, 3 columnas\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 7), sharey=True)\n",
    "\n",
    "# Lista de dataframes y sus t칤tulos correspondientes\n",
    "dfs = [df_similaridad_total_v3, df_similaridad_total_v5, df_similaridad_total_v7]\n",
    "titulos = [\n",
    "    'Ventana 3 D칤as\\nDistribuci칩n Levy - Entrop칤a Baja',\n",
    "    'Ventana 5 D칤as\\nDistribuci칩n Levy - Entrop칤a Alta',\n",
    "    'Ventana 7 D칤as\\nDistribuci칩n Levy - Entrop칤a Alta'\n",
    "]\n",
    "\n",
    "# 2. Iterar sobre los ejes y los datos para generar los KDEs\n",
    "for i, df in enumerate(dfs):\n",
    "    # Convertimos de formato ancho a largo para que Seaborn reconozca los modelos como categor칤as\n",
    "    df_long = df.melt(var_name='Modelo', value_name='Similaridad')\n",
    "    \n",
    "    sns.kdeplot(\n",
    "        data=df_long,\n",
    "        x=\"Similaridad\",\n",
    "        hue=\"Modelo\",\n",
    "        fill=True,\n",
    "        ax=axes[i],\n",
    "        palette=\"viridis\", # Una paleta colorida ayuda a diferenciar modelos\n",
    "        alpha=0.4,\n",
    "        linewidth=1.5\n",
    "    )\n",
    "    \n",
    "    axes[i].set_title(titulos[i], fontsize=13, fontweight='bold')\n",
    "    axes[i].set_xlabel('Coeficiente de Similaridad')\n",
    "    \n",
    "    # Solo el primer gr치fico lleva etiqueta en el eje Y\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel('Densidad de Probabilidad')\n",
    "    else:\n",
    "        axes[i].set_ylabel('')\n",
    "\n",
    "# 3. Ajustes de la leyenda para que no tape el gr치fico si hay muchos modelos\n",
    "for ax in axes:\n",
    "    sns.move_legend(ax,  fontsize='small', title=\"Modelos\",  loc='upper center', bbox_to_anchor=(0.5, -0.2))\n",
    "\n",
    "# Ajustes finales\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912c1783-f99a-489c-9a77-dfd1c7dadda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configuraci칩n de la figura: 1 fila, 3 columnas\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 8), sharey=True)\n",
    "\n",
    "# Lista de dataframes y sus t칤tulos correspondientes\n",
    "dfs = [df_similaridad_total_v3, df_similaridad_total_v5, df_similaridad_total_v7]\n",
    "titulos = [\n",
    "    'Ventana 3 D칤as\\nDistribuci칩n Levy - Entrop칤a Baja',\n",
    "    'Ventana 5 D칤as\\nDistribuci칩n Levy - Entrop칤a Alta',\n",
    "    'Ventana 7 D칤as\\nDistribuci칩n Levy - Entrop칤a Alta'\n",
    "]\n",
    "\n",
    "# 2. Iterar sobre los ejes y los datos para generar las distribuciones acumuladas\n",
    "for i, df in enumerate(dfs):\n",
    "    # Convertimos de formato ancho a largo\n",
    "    df_long = df.melt(var_name='Modelo', value_name='Similaridad')\n",
    "    \n",
    "    sns.kdeplot(\n",
    "        data=df_long,\n",
    "        x=\"Similaridad\",\n",
    "        hue=\"Modelo\",\n",
    "        cumulative=True,     # Activamos la distribuci칩n acumulada\n",
    "        fill=False,          # Solo mostramos la l칤nea\n",
    "        ax=axes[i],\n",
    "        palette=\"viridis\",\n",
    "        linewidth=2,\n",
    "        alpha=0.8\n",
    "    )\n",
    "    \n",
    "    axes[i].set_title(titulos[i], fontsize=13, fontweight='bold')\n",
    "    axes[i].set_xlabel('Coeficiente de Similaridad')\n",
    "    \n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel('Probabilidad Acumulada (CDF)')\n",
    "    else:\n",
    "        axes[i].set_ylabel('')\n",
    "\n",
    "# 3. Ajustes de la leyenda abajo para no obstruir las l칤neas\n",
    "for ax in axes:\n",
    "    sns.move_legend(\n",
    "        ax, \n",
    "        loc='upper center', \n",
    "        bbox_to_anchor=(0.5, -0.2), \n",
    "        ncol=1,             # Agrupamos en 5 columnas para que sea legible\n",
    "        fontsize='x-small', \n",
    "        title=\"Modelos\"\n",
    "    )\n",
    "\n",
    "# Ajustes finales de espaciado\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.25) # Espacio para la leyenda\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42cef19-0680-462f-b440-fd14a8dc05ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
